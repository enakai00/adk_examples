{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9320905-016f-4ad9-9402-70a94cde7c1d",
   "metadata": {},
   "source": [
    "# Deploying ADK agent on Agent Engine from source files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbde7f-a443-49e2-83f2-373f5baa9ca8",
   "metadata": {},
   "source": [
    "This notebook provides a technical guide for deploying an AI agent built with the **Google Agent Development Kit (ADK)** to **Agent Engine** (Vertex AI Reasoning Engine) using local source files.\n",
    "\n",
    "## Summary\n",
    "\n",
    "The standard deployment method for Vertex AI Agent Engine often relies on \"on-the-fly\" serialization (using tools like `cloudpickle`) of existing Python objects. However, this process frequently fails when an agent object contains complex, non-serializable components such as active network connections, specific database drivers, or complex nested modules.\n",
    "\n",
    "**The Solution:** This notebook demonstrates the **Source-Based Deployment** approach. By providing the path to your source code and specifying the entry point, Agent Engine builds the environment and instantiates the object directly in the cloud. This bypasses local serialization errors and ensures a more robust deployment for production-grade agents.\n",
    "\n",
    "---\n",
    "\n",
    "## Deployment Steps\n",
    "\n",
    "The notebook follows a structured workflow to move your local ADK code to a managed cloud endpoint:\n",
    "\n",
    "1. **Environment Initialization:** Sets up the Vertex AI SDK with your Project ID and target Location (e.g., `us-central1`).\n",
    "2. **Source Preparation:**\n",
    "* Creates a local directory (`sample_agent`) containing your logic.\n",
    "* Defines `agent.py`, where the `AdkApp` and `LlmAgent` are instantiated.\n",
    "* Defines `requirements.txt` to ensure the cloud environment has the correct versions of `google-adk` and related libraries.\n",
    "\n",
    "\n",
    "3. **Client Configuration:** Initializes the `vertexai.Client` using `v1beta1` features required for Agent Engine management.\n",
    "4. **Deployment Configuration:** Defines a configuration dictionary that maps the local source to the cloud:\n",
    "* `source_packages`: The directory containing your code.\n",
    "* `entrypoint_module`: The Python module to run (e.g., `sample_agent.agent`).\n",
    "* `entrypoint_object`: The specific variable name of your `AdkApp` instance.\n",
    "\n",
    "\n",
    "5. **Two-Phase Deployment (The \"Resource Name\" Cycle):**\n",
    "* **Phase 1:** Creates a dummy deployment to generate a unique **Reasoning Engine Resource Name**.\n",
    "* **Phase 2:** Updates the local source code with this resource name (required by `AdkApp`) and redeploys the finalized agent.\n",
    "\n",
    "\n",
    "6. **Validation:** Implements a `ChatClient` to test the deployed agent via asynchronous streaming queries.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Considerations\n",
    "\n",
    "### 1. Avoiding Serialization Errors\n",
    "\n",
    "By using `source_packages` and `entrypoint_module`, you are telling Vertex AI to \"install and run\" your code rather than \"copy a snapshot of memory.\" This is the recommended path for any agent that uses complex third-party libraries or internal state that cannot be easily pickled.\n",
    "\n",
    "### 2. The `app_name` Requirement\n",
    "\n",
    "In the ADK framework, the `AdkApp` object requires its own GCP resource name (the `projects/.../reasoningEngines/...` string) to function correctly for session management. Because this name isn't known until *after* the first deployment, you must:\n",
    "\n",
    "* Deploy with a placeholder.\n",
    "* Retrieve the generated name.\n",
    "* Update the source code and redeploy.\n",
    "\n",
    "### 3. API Versioning\n",
    "\n",
    "This notebook utilizes the `v1beta1` API version via `HttpOptions`. This is necessary for accessing the latest Agent Engine features within the Vertex AI SDK.\n",
    "\n",
    "### 4. Dependency Management\n",
    "\n",
    "Ensure that all libraries imported in your `agent.py` are explicitly listed in your `requirements.txt`. The cloud environment is built from scratch based on this file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198b9a7d-9e67-4b32-92b5-4e5a31b1eb72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from google.genai.types import HttpOptions\n",
    "\n",
    "[PROJECT_ID] = !gcloud config list --format 'value(core.project)'\n",
    "LOCATION = 'us-central1'\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d28a124-ee9f-4e31-b120-ef6bec2a387a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p sample_agent\n",
    "cat <<'EOF' >sample_agent/agent.py\n",
    "from vertexai.agent_engines import AdkApp\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.sessions import VertexAiSessionService\n",
    "\n",
    "root_agent = LlmAgent(\n",
    "    name='frientdly_agent',\n",
    "    model='gemini-2.5-flash',\n",
    "    instruction='Be friendly.',\n",
    ")\n",
    "\n",
    "def session_service_builder():\n",
    "    return VertexAiSessionService()\n",
    "\n",
    "# entrypoint_object\n",
    "app = AdkApp(\n",
    "    agent=root_agent,\n",
    "    # Need to be replaced by the full Reasoning Enigne resource name.\n",
    "    app_name='__APP_NAME__',\n",
    "    # Need to explicitly specify VertexAiSessionService.\n",
    "    session_service_builder=session_service_builder,\n",
    ")\n",
    "EOF\n",
    "\n",
    "cat <<'EOF' >sample_agent/requirements.txt\n",
    "google-adk==1.21.0\n",
    "google-cloud-aiplatform==1.132.0\n",
    "google-genai==1.56.0\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0381bca0-e2ae-46e9-abff-0896bac7b3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = 'frientdly_agent'\n",
    "\n",
    "client = vertexai.Client(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    http_options=HttpOptions(\n",
    "        api_version='v1beta1',\n",
    "        base_url=f'https://{LOCATION}-aiplatform.googleapis.com/'\n",
    "    ),\n",
    ")\n",
    "\n",
    "config = {\n",
    "        'display_name': DISPLAY_NAME,\n",
    "        'source_packages': ['sample_agent'],\n",
    "        'entrypoint_module': 'sample_agent.agent',\n",
    "        'entrypoint_object': 'app',\n",
    "        'requirements_file': 'sample_agent/requirements.txt',\n",
    "        'class_methods': [\n",
    "            {\n",
    "                'name': 'async_stream_query',\n",
    "                'api_mode': 'async_stream',\n",
    "                'description': 'Stream responses from the agent for a given query.',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'input': {'type': 'string', 'description': 'The user query'},\n",
    "                        'config': {'type': 'object', 'description': 'Optional runtime config'}\n",
    "                    },\n",
    "                    'required': ['input']\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'name': 'async_create_session',\n",
    "                'api_mode': 'async',\n",
    "                'description': 'Create a new managed session.'\n",
    "            }\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9187f6fd-018c-4207-9923-933500546e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_resource_name(display_name):\n",
    "    resource_name = None\n",
    "    for item in client.agent_engines.list():\n",
    "        if item.api_resource.display_name == display_name:\n",
    "            resource_name = item.api_resource.name\n",
    "            break\n",
    "    return resource_name\n",
    "\n",
    "if not get_resource_name(DISPLAY_NAME):\n",
    "    # Deply dummy agent to assign Reasoning Engine resource name.\n",
    "    remote_agent = client.agent_engines.create(\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "# Set the resource name as app_name, and update the agent.\n",
    "resource_name = get_resource_name(DISPLAY_NAME)\n",
    "!sed -i 's:__APP_NAME__:{resource_name}:g' sample_agent/agent.py\n",
    "remote_agent = client.agent_engines.update(\n",
    "    name=resource_name,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a43b654d-1a6c-43af-ad66-84929fb3a3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentEngine(api_resource.name='projects/879055303739/locations/us-central1/reasoningEngines/6183817221844762624')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_agent = client.agent_engines.get(name=resource_name)\n",
    "remote_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72be7f74-133b-41f8-94f7-45dbd7d706df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chat client to test AdkApp\n",
    "class ChatClient:\n",
    "    def __init__(self, app, user_id='default_user'):\n",
    "        self._app = app\n",
    "        self._user_id = user_id\n",
    "        self._session_id = None\n",
    "\n",
    "    async def async_stream_query(self, message):\n",
    "        if not self._session_id:\n",
    "            session = await self._app.async_create_session(\n",
    "                user_id=self._user_id,\n",
    "            )\n",
    "            self._session_id = getattr(session, 'id', None) or session['id']\n",
    "\n",
    "        result = []\n",
    "        async for event in self._app.async_stream_query(\n",
    "            user_id=self._user_id,\n",
    "            session_id=self._session_id,\n",
    "            message=message,\n",
    "        ):\n",
    "#            print('====')\n",
    "#            print(event)\n",
    "#            print('====')\n",
    "            if ('content' in event and 'parts' in event['content']):\n",
    "                response = '\\n'.join(\n",
    "                    [p['text'] for p in event['content']['parts'] if 'text' in p]\n",
    "                )\n",
    "                if response:\n",
    "                    print(response)\n",
    "                    result.append(response)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4be4fbc9-7c27-4e20-82e2-072749e850bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! I'm doing very well, thank you for asking. I'm busy helping users like you and learning new things every day, which I find quite enjoyable.\n",
      "\n",
      "How about you? How are you doing today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "client = ChatClient(remote_agent)\n",
    "_ = await client.async_stream_query('how are you?')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
