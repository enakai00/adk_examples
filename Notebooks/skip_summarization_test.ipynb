{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "062304ce-5604-4a62-8897-70a62b7e2053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-adk                              1.5.0\n",
      "google-cloud-aiplatform                 1.101.0\n",
      "google-genai                            1.21.1\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -E \"(adk|genai|aiplatform)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8722e641-cd9a-4e73-9622-427ea35c8bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy, datetime, json, os, pprint, time, uuid\n",
    "import vertexai\n",
    "from google.genai.types import Part, Content\n",
    "from google.adk.agents.llm_agent import LlmAgent\n",
    "from google.adk.artifacts import InMemoryArtifactService\n",
    "from google.adk.memory.in_memory_memory_service import InMemoryMemoryService\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools import google_search\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "\n",
    "[PROJECT_ID] = !gcloud config list --format 'value(core.project)'\n",
    "LOCATION = 'us-central1'\n",
    "vertexai.init(\n",
    "    project=PROJECT_ID, location=LOCATION,\n",
    "    staging_bucket=f'gs://{PROJECT_ID}'\n",
    ")\n",
    "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n",
    "os.environ['GOOGLE_CLOUD_LOCATION'] = LOCATION\n",
    "os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d94ab67e-99e0-498d-8095-81ca07156c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LocalApp:\n",
    "    def __init__(self, agent, app_name='default_app', user_id='default_user'):\n",
    "        self._agent = agent\n",
    "        self._app_name = app_name\n",
    "        self._user_id = user_id\n",
    "        self._runner = Runner(\n",
    "            app_name=self._app_name,\n",
    "            agent=self._agent,\n",
    "            artifact_service=InMemoryArtifactService(),\n",
    "            session_service=InMemorySessionService(),\n",
    "            memory_service=InMemoryMemoryService(),\n",
    "        )\n",
    "        self._session = None\n",
    "        \n",
    "    async def stream(self, query):\n",
    "        if not self._session:\n",
    "            self._session = await self._runner.session_service.create_session(\n",
    "                app_name=self._app_name,\n",
    "                user_id=self._user_id,\n",
    "                session_id=uuid.uuid4().hex,\n",
    "            )\n",
    "        content = Content(role='user', parts=[Part.from_text(text=query)])\n",
    "        async_events = self._runner.run_async(\n",
    "            user_id=self._user_id,\n",
    "            session_id=self._session.id,\n",
    "            new_message=content,\n",
    "        )\n",
    "        result = []\n",
    "        async for event in async_events:\n",
    "            if DEBUG:\n",
    "                print(f'===\\n{event}\\n===')\n",
    "            if (event.content and event.content.parts):\n",
    "                response = '\\n'.join([p.text for p in event.content.parts if p.text])\n",
    "                if response:\n",
    "                    print(response)\n",
    "                    result.append(response)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bd94203-da07-413e-9d85-94cfcfbaa8bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "google_search_tool = LlmAgent(\n",
    "    model='gemini-2.0-flash',\n",
    "    name='google_search_tool',\n",
    "    instruction=\"\"\"\n",
    "    You are a Google Search expert.\n",
    "    \"\"\",\n",
    "    tools=[google_search],\n",
    ")\n",
    "\n",
    "instruction = '''\n",
    "You are a friendly AI assistant that answers user's queries.\n",
    "\n",
    "Step1. Use google_search_tool to get the latest information.\n",
    "Step2. Give answers based on the latest and objective information.\n",
    "\n",
    "[Format instruction]\n",
    "Output in English, in plain text only.\n",
    "Avoid adding citation marks such as [1][2].\n",
    "'''\n",
    "\n",
    "# With skip_summarization=False\n",
    "search_agent1 = LlmAgent(\n",
    "    name='search_agent1',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    description='Agent to answer questions using Google Search.',\n",
    "    instruction=instruction,\n",
    "    tools=[AgentTool(google_search_tool, skip_summarization=False)],\n",
    ")\n",
    "\n",
    "# With skip_summarization=True\n",
    "search_agent2 = LlmAgent(\n",
    "    name='search_agent2',\n",
    "    model='gemini-2.0-flash-001',\n",
    "    description='Agent to answer questions using Google Search.',\n",
    "    instruction=instruction,\n",
    "    tools=[AgentTool(google_search_tool, skip_summarization=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ca94d-a708-44e7-87c9-336b77010b5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "With `skip_summarization=False`, the agent generate a response based on the `google_search_tool`'s result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe01b19-76b3-4eac-a2a3-5796386d06cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id='adk-63605f31-c3b5-45dc-b065-ac2e3f2aaf0e', args={'request': 'weather in Seoul'}, name='google_search_tool'), function_response=None, text=None)], role='model') grounding_metadata=None partial=None turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=9, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=9)], prompt_token_count=121, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=121)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=130, traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>) invocation_id='e-d42ebf96-34b8-4854-9681-872b5338bc83' author='search_agent1' actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=set() branch=None id='xuqFPmC2' timestamp=1752083126.005468\n",
      "===\n",
      "===\n",
      "content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=FunctionResponse(will_continue=None, scheduling=None, id='adk-63605f31-c3b5-45dc-b065-ac2e3f2aaf0e', name='google_search_tool', response={'result': 'The weather in Seoul, South Korea is currently clear with a temperature of 81°F (27°C), but it feels like 82°F (28°C). The humidity is around 62%.\\n\\nThe forecast for the next 15 days is as follows:\\n\\n*   **Thursday, July 10:** Clear, with a high of 95°F (35°C) and a low of 79°F (26°C). There is a 10% chance of precipitation.\\n*   **Friday, July 11:** Clear, with a high of 93°F (34°C) and a low of 75°F (24°C).\\n*   **Saturday, July 12:** Clear, with a high of 95°F (35°C) and a low of 75°F (24°C).\\n*   **Sunday, July 13:** Clear with periodic rain, with a high of 90°F (32°C) and a low of 75°F (24°C).\\n*   **Monday, July 14:** Clear with periodic rain, with a high of 90°F (32°C) and a low of 75°F (24°C). There is a 10% chance of rain.\\n*   **Tuesday, July 15:** Clear with periodic rain, with a high of 86°F (30°C) and a low of 73°F (23°C). There is a 40% chance of rain.\\n*   **Wednesday, July 16:** Clear with periodic rain, with a high of 84°F (29°C) and a low of 75°F (24°C). There is a 90% chance of rain.\\n*   **Thursday, July 17:** Rainy but periodically clear, with a high of 90°F (32°C) and a low of 73°F (23°C). There is a 90% chance of rain.\\n*   **Friday, July 18:** Rain that periodically stops, with a high of 86°F (30°C) and a low of 75°F (24°C). There is a 90% chance of rain.\\n*   **Saturday, July 19:** Rainy but periodically clear, with a high of 82°F (28°C) and a low of 77°F (25°C). There is a 90% chance of rain.\\n*   **Sunday, July 20:** Clear with periodic rain, with a high of 88°F (31°C) and a low of 75°F (24°C). There is a 90% chance of rain.\\n*   **Monday, July 21:** Rainy but periodically clear, with a high of 88°F (31°C) and a low of 77°F (25°C). There is a 40% chance of rain.\\n*   **Tuesday, July 22:** Clear with periodic rain, with a high of 88°F (31°C) and a low of 77°F (25°C). There is a 10% chance of rain.\\n*   **Wednesday, July 23:** Clear with periodic rain, with a high of 88°F (31°C) and a low of 77°F (25°C). There is a 90% chance of rain.\\n*   **Thursday, July 24:** Clear with periodic rain, with a high of 93°F (34°C) and a low of 77°F (25°C). There is a 10% chance of rain.\\n'}), text=None)], role='user') grounding_metadata=None partial=None turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-d42ebf96-34b8-4854-9681-872b5338bc83' author='search_agent1' actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='l7XuDIY0' timestamp=1752083133.211378\n",
      "===\n",
      "===\n",
      "content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='The weather in Seoul, South Korea is currently clear with a temperature of 81°F (27°C), but it feels like 82°F (28°C). The humidity is around 62%. The forecast for the next 15 days includes high temperatures in the 80s and 90s Fahrenheit, with a significant chance of rain from July 16th to July 23rd.\\n')], role='model') grounding_metadata=None partial=None turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=93, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=93)], prompt_token_count=1012, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=1012)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=1105, traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>) invocation_id='e-d42ebf96-34b8-4854-9681-872b5338bc83' author='search_agent1' actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='jAkpBY9S' timestamp=1752083133.214233\n",
      "===\n",
      "The weather in Seoul, South Korea is currently clear with a temperature of 81°F (27°C), but it feels like 82°F (28°C). The humidity is around 62%. The forecast for the next 15 days includes high temperatures in the 80s and 90s Fahrenheit, with a significant chance of rain from July 16th to July 23rd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = LocalApp(search_agent1)\n",
    "DEBUG=True\n",
    "query = '''\n",
    "Get the wheather news in Seoul.\n",
    "'''\n",
    "_ = await client.stream(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c155b4d9-8858-47d5-b16d-e6ade4c6b5aa",
   "metadata": {},
   "source": [
    "With `skip_summarization=True`, the agent stops working when it receives a function call response from the `google_search_tool`'s result. **It doesn't generate any text reposonce.** So the application (calling the agent) needs to parse the funcion call response event by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8be462-918b-4df7-b168-707118bf5787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id='adk-c54150ba-60b4-4c5c-a089-e19eeefcb992', args={'request': 'weather in Seoul'}, name='google_search_tool'), function_response=None, text=None)], role='model') grounding_metadata=None partial=None turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=9, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=9)], prompt_token_count=121, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=121)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=130, traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>) invocation_id='e-a91ca488-1bcd-411b-bf92-7b4512250ad5' author='search_agent2' actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=set() branch=None id='08dnLYch' timestamp=1752083151.248715\n",
      "===\n",
      "===\n",
      "content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=FunctionResponse(will_continue=None, scheduling=None, id='adk-c54150ba-60b4-4c5c-a089-e19eeefcb992', name='google_search_tool', response={'result': 'The weather in Seoul, South Korea is currently clear with a temperature of 81°F (27°C), but it feels like 82°F (28°C). The humidity is around 62%.\\n\\nHere is the forecast for the next few days:\\n\\n*   **Thursday, July 10:** Clear, with a high of 95°F (35°C) and a low of 79°F (26°C). There is a 10% chance of precipitation.\\n*   **Friday, July 11:** Clear, with a high of 93°F (34°C) and a low of 75°F (24°C).\\n*   **Saturday, July 12:** Clear, with a high of 95°F (35°C) and a low of 75°F (24°C).\\n*   **Sunday, July 13:** Clear with periodic rain, with a high of 90°F (32°C) and a low of 75°F (24°C).\\n*   **Monday, July 14:** Clear with periodic rain, with a high of 90°F (32°C) and a low of 75°F (24°C). There is a 10% chance of rain during the day.\\n\\n'}), text=None)], role='user') grounding_metadata=None partial=None turn_complete=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None invocation_id='e-a91ca488-1bcd-411b-bf92-7b4512250ad5' author='search_agent2' actions=EventActions(skip_summarization=True, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}) long_running_tool_ids=None branch=None id='SEfuPUMx' timestamp=1752083155.519841\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "client = LocalApp(search_agent2)\n",
    "DEBUG=True\n",
    "query = '''\n",
    "Get the wheather news in Seoul.\n",
    "'''\n",
    "_ = await client.stream(query)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
