{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f08708d3-0f11-41a9-a34f-7da6d3a34a8f",
   "metadata": {},
   "source": [
    "# ADK を Workflow tool として無理やり利用するサンプル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0edb6-37a7-4a09-b9cf-33316acfac67",
   "metadata": {},
   "source": [
    "## 事前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a29ece-5ca4-41b5-a1e6-dcef27b266c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy, json, os, re, uuid\n",
    "import vertexai\n",
    "from google.genai.types import Part, Content, FunctionCall\n",
    "from google.adk.agents.llm_agent import LlmAgent\n",
    "from google.adk.artifacts import InMemoryArtifactService\n",
    "from google.adk.memory.in_memory_memory_service import InMemoryMemoryService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "\n",
    "from google.adk.agents.callback_context import CallbackContext\n",
    "from google.adk.models import LlmResponse, LlmRequest\n",
    "from google.adk.tools import ToolContext\n",
    "\n",
    "[PROJECT_ID] = !gcloud config list --format 'value(core.project)'\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n",
    "os.environ['GOOGLE_CLOUD_LOCATION'] = LOCATION\n",
    "os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d5c35b-45e7-4fe9-9bdf-5bd924d775a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LocalApp:\n",
    "    def __init__(self, agent, user_id='default_user', state={}):\n",
    "        self._agent = agent\n",
    "        self._user_id = user_id\n",
    "        self._runner = Runner(\n",
    "            app_name=self._agent.name,\n",
    "            agent=self._agent,\n",
    "            artifact_service=InMemoryArtifactService(),\n",
    "            session_service=InMemorySessionService(),\n",
    "            memory_service=InMemoryMemoryService(),\n",
    "        )\n",
    "        self._state = state\n",
    "        self._session = None\n",
    "        \n",
    "    async def stream(self, query):\n",
    "        if not self._session:\n",
    "            self._session = await self._runner.session_service.create_session(\n",
    "                app_name=self._agent.name,\n",
    "                user_id=self._user_id,\n",
    "                session_id=uuid.uuid4().hex,\n",
    "                state=self._state,\n",
    "            )\n",
    "        content = Content(role='user', parts=[Part.from_text(text=query)])\n",
    "        async_events = self._runner.run_async(\n",
    "            user_id=self._user_id,\n",
    "            session_id=self._session.id,\n",
    "            new_message=content,\n",
    "        )\n",
    "        result = []\n",
    "        async for event in async_events:\n",
    "            if DEBUG:\n",
    "                print(f'----\\n{event}\\n----')\n",
    "            if (event.content and event.content.parts):\n",
    "                response = '\\n'.join([p.text for p in event.content.parts if p.text])\n",
    "                if response:\n",
    "                    print(response)\n",
    "                    result.append(response)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c045490-977f-4d28-a74c-bb3dd8b60f31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Workflow 制御のコールバック関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17987dd3-8914-4ab4-8373-3e9c9d010d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def workflow_tool_callback(tool_name):\n",
    "    async def before_model_callback(\n",
    "        callback_context: CallbackContext, llm_request: LlmRequest\n",
    "    ) -> LlmResponse:\n",
    "        \n",
    "        agent_name = callback_context.agent_name\n",
    "\n",
    "        last_part = callback_context._invocation_context.session.events[-1].content.parts[-1]\n",
    "        if last_part.function_response and last_part.function_response.name == 'transfer_to_agent':\n",
    "            is_transferred = True\n",
    "        else:\n",
    "            is_transferred = False\n",
    "\n",
    "        # Finish when transferred to root_agent.\n",
    "        if agent_name == 'root_agent' and is_transferred:\n",
    "            return LlmResponse(\n",
    "                content=Content(role='model', parts=[Part(text='done')]) \n",
    "            )\n",
    "\n",
    "        # Run tool when directly called or transferred to me.\n",
    "        if (not llm_request.contents) or is_transferred:\n",
    "            part = Part(function_call=FunctionCall(name=tool_name, args={}))\n",
    "            return LlmResponse(\n",
    "                content=Content(role='model', parts=[part]) \n",
    "            )\n",
    "\n",
    "        # Transfer to next_agent\n",
    "        response = llm_request.contents[-1].parts[-1].function_response.response\n",
    "        if 'next_agent' in response:\n",
    "            next_agent = response['next_agent']\n",
    "        else:\n",
    "            next_agent = agent_name # Default to myself\n",
    "        part = Part(function_call=FunctionCall(\n",
    "                        name='transfer_to_agent',\n",
    "                        args={'agent_name': next_agent}))\n",
    "        return LlmResponse(\n",
    "            content=Content(role='model', parts=[part]) \n",
    "        )\n",
    "    \n",
    "    return before_model_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77457307-4368-44a8-a0a5-c62f30d907ef",
   "metadata": {},
   "source": [
    "## サンプル実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96dc216-a174-4cc7-9f34-f6caa362bbcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "`ping_agent` は `ping_tool()` を実行して、`pong_agent` に遷移する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ed6841-5a6b-4d06-80d5-61e373d45277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ping_tool(tool_context: ToolContext) -> dict:\n",
    "    count = tool_context.state.get('count')\n",
    "    count -= 1\n",
    "    tool_context.state['count'] = count\n",
    "\n",
    "    print('ping', count)\n",
    "    return {'next_agent': 'pong_agent'}\n",
    "\n",
    "\n",
    "ping_agent = LlmAgent(\n",
    "    model='gemini-2.0-flash-001', # not used\n",
    "    name='ping_agent',\n",
    "    description='An agent that always run ping_tool.',\n",
    "    instruction='',\n",
    "    tools=[ping_tool],\n",
    "    before_model_callback = workflow_tool_callback('ping_tool'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08310468-566c-4b56-be76-daf221a1d06b",
   "metadata": {
    "tags": []
   },
   "source": [
    "`pong_agent` は `pong_tool()` を実行して、\n",
    "\n",
    "- `count <= 0`: `root_agent` に遷移する。\n",
    "- `count % 2 == 0`: `pong_agent` に遷移する。\n",
    "- `else`: `ping_agent` に遷移する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3af5423-318c-4c34-b1e9-c2bee77e455c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pong_tool(tool_context: ToolContext) -> dict:\n",
    "    count = tool_context.state.get('count')\n",
    "    count -= 1\n",
    "    tool_context.state['count'] = count\n",
    "\n",
    "    print('pong', count)\n",
    "    if count <= 0:\n",
    "        return {'next_agent': 'root_agent'}\n",
    "    elif count % 2 == 0:\n",
    "        return {'next_agent': 'pong_agent'}\n",
    "    else:\n",
    "        return {'next_agent': 'ping_agent'}\n",
    "\n",
    "\n",
    "pong_agent = LlmAgent(\n",
    "    model='gemini-2.0-flash-001', # not used\n",
    "    name='pong_agent',\n",
    "    description='An agent that always run pong_tool.',\n",
    "    instruction='',\n",
    "    tools=[pong_tool],\n",
    "    before_model_callback = workflow_tool_callback('pong_tool'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f8e61a-7cef-41df-87f4-a7856224a667",
   "metadata": {},
   "source": [
    "`root_agent` は初回呼び出し時に `ping_agent` に遷移する。\n",
    "\n",
    "他のエージェントから遷移してきた場合は、そこで終了する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d6827c-95f5-4daa-a64c-a3cbc7386cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def root_tool(tool_context: ToolContext) -> dict:\n",
    "    return {'next_agent': 'ping_agent'}\n",
    "\n",
    "root_agent = LlmAgent(\n",
    "    model='gemini-2.0-flash-001', # not used\n",
    "    name='root_agent',\n",
    "    description='An agent that always run root_tool.',\n",
    "    instruction='',\n",
    "    sub_agents = [\n",
    "        copy.deepcopy(ping_agent),\n",
    "        copy.deepcopy(pong_agent),\n",
    "    ],\n",
    "    tools = [root_tool],\n",
    "    before_model_callback = workflow_tool_callback('root_tool'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27c957-1c8f-4fff-98ab-34b1665991e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "`root_agent` -> `ping_agetn` -> `pong_agent` -> ... -> `root_agent` のワークフローが実行される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e065961c-0800-4611-95e2-a2c81a33d9e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ping 5\n",
      "pong 4\n",
      "pong 3\n",
      "ping 2\n",
      "pong 1\n",
      "ping 0\n",
      "pong -1\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "state = {'count': 6}\n",
    "client = LocalApp(root_agent, state=state)\n",
    "\n",
    "DEBUG = False\n",
    "_ = await client.stream('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5647643d-048c-46c3-bb77-88f12831d5eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LLM の応答とは関係なく強制的に Transfer させる実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5734cf2-5270-4655-847c-e75e7b07f927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def force_transfer_callback(next_agent):\n",
    "    async def after_model_callback(\n",
    "        callback_context: CallbackContext, llm_response: LlmResponse\n",
    "    ) -> LlmResponse:\n",
    "        parts = copy.deepcopy(llm_response.content.parts)\n",
    "        part = Part(function_call=FunctionCall(\n",
    "                        name='transfer_to_agent',\n",
    "                        args={'agent_name': next_agent}))\n",
    "        parts.append(part)\n",
    "        return LlmResponse(\n",
    "            content=Content(role='model', parts=parts) \n",
    "        )\n",
    "    \n",
    "    return after_model_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f186eb0-a043-4020-a234-2e95544d384e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "echo_agent = LlmAgent(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    name='echo_agent',\n",
    "    description='An agent that repeat the last output text.',\n",
    "    instruction='Say \"Echo: \" first, and then repeat the last output text.',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34604c97-88f0-437e-9bb0-07c1e51b10ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_agent = LlmAgent(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    name='root_agent',\n",
    "    description='greeting!',\n",
    "    instruction='',\n",
    "    sub_agents = [\n",
    "        copy.deepcopy(echo_agent),\n",
    "    ],\n",
    "    after_model_callback = force_transfer_callback('echo_agent'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ae0a362-05db-4da2-8390-f0184b5457bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm doing well, thank you for asking!\n",
      "\n",
      "Echo: I'm doing well, thank you for asking!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = LocalApp(root_agent)\n",
    "\n",
    "DEBUG = False\n",
    "_ = await client.stream('How are you doing?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9f4fb-79e5-4361-ba8d-72f73ffa8435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
